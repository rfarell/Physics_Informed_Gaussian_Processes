{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symplectic Spectrum Gaussian Processes\n",
    "\n",
    "The original code from the author is available here https://github.com/yusuk-e/SSGP. This notebook refactors/implements it here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autograd in /usr/local/Caskroom/miniforge/base/envs/torch/lib/python3.11/site-packages (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.12 in /usr/local/Caskroom/miniforge/base/envs/torch/lib/python3.11/site-packages (from autograd) (1.26.0)\n",
      "Requirement already satisfied: future>=0.15.2 in /usr/local/Caskroom/miniforge/base/envs/torch/lib/python3.11/site-packages (from autograd) (0.18.3)\n",
      "Requirement already satisfied: torchdiffeq in /usr/local/Caskroom/miniforge/base/envs/torch/lib/python3.11/site-packages (0.2.3)\n",
      "Requirement already satisfied: torch>=1.3.0 in /usr/local/Caskroom/miniforge/base/envs/torch/lib/python3.11/site-packages (from torchdiffeq) (2.1.0)\n",
      "Requirement already satisfied: scipy>=1.4.0 in /usr/local/Caskroom/miniforge/base/envs/torch/lib/python3.11/site-packages (from torchdiffeq) (1.11.3)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/Caskroom/miniforge/base/envs/torch/lib/python3.11/site-packages (from scipy>=1.4.0->torchdiffeq) (1.26.0)\n",
      "Requirement already satisfied: filelock in /usr/local/Caskroom/miniforge/base/envs/torch/lib/python3.11/site-packages (from torch>=1.3.0->torchdiffeq) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/Caskroom/miniforge/base/envs/torch/lib/python3.11/site-packages (from torch>=1.3.0->torchdiffeq) (4.8.0)\n",
      "Requirement already satisfied: sympy in /usr/local/Caskroom/miniforge/base/envs/torch/lib/python3.11/site-packages (from torch>=1.3.0->torchdiffeq) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/Caskroom/miniforge/base/envs/torch/lib/python3.11/site-packages (from torch>=1.3.0->torchdiffeq) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/Caskroom/miniforge/base/envs/torch/lib/python3.11/site-packages (from torch>=1.3.0->torchdiffeq) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/Caskroom/miniforge/base/envs/torch/lib/python3.11/site-packages (from torch>=1.3.0->torchdiffeq) (2023.9.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/Caskroom/miniforge/base/envs/torch/lib/python3.11/site-packages (from jinja2->torch>=1.3.0->torchdiffeq) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/Caskroom/miniforge/base/envs/torch/lib/python3.11/site-packages (from sympy->torch>=1.3.0->torchdiffeq) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install autograd\n",
    "! pip install torchdiffeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symplectic Spectrum Gaussian Processes | 2022\n",
    "# Yusuke Tanaka\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def check_dir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "def csv_read(file):\n",
    "    f = open(file)\n",
    "    csvReader = csv.reader(f)\n",
    "    D = []\n",
    "    for row in csvReader:\n",
    "        D.append(row)\n",
    "    return D\n",
    "\n",
    "def csv_write(file, D):\n",
    "    f = open(file,'w')\n",
    "    csvWriter = csv.writer(f,lineterminator='\\n')\n",
    "    if np.ndim(D) == 1:\n",
    "        csvWriter.writerow(D)\n",
    "    elif np.ndim(D) == 2:\n",
    "        for i in range(np.shape(D)[0]):\n",
    "            line = D[i]\n",
    "            csvWriter.writerow(line)\n",
    "    f.close()\n",
    "\n",
    "def pkl_read(file):\n",
    "    f = open(file, 'rb')\n",
    "    D = pickle.load(f)\n",
    "    f.close()\n",
    "    return D\n",
    "\n",
    "def pkl_write(file, D):\n",
    "    f = open(file,'wb')\n",
    "    pickle.dump(D,f,protocol=4)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symplectic Spectrum Gaussian Processes | 2022\n",
    "# Yusuke Tanaka\n",
    "\n",
    "import pdb\n",
    "import json\n",
    "import argparse\n",
    "import math\n",
    "import autograd.numpy as np\n",
    "import autograd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchdiffeq import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import os, sys\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "%pwd\n",
    "THIS_DIR = %pwd  # This will set THIS_DIR to the current working directory\n",
    "\n",
    "xmin = -3.2; xmax = 3.2; ymin = -3.2; ymax = 3.2\n",
    "DPI = 200\n",
    "FORMAT = 'pdf'\n",
    "LINE_SEGMENTS = 10\n",
    "ARROW_SCALE = 100\n",
    "ARROW_WIDTH = 6e-3\n",
    "LINE_WIDTH = 2\n",
    "\n",
    "class Args:\n",
    "    def __init__(self, dictionary):\n",
    "        for key, value in dictionary.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "args = Args({\n",
    "    'batch_time': 1,         # Provided in command line args\n",
    "    'learn_rate': 1e-3,      # Default from get_args()\n",
    "    'total_steps': 100,      # Provided in command line args\n",
    "    'print_every': 100,      # Default from get_args()\n",
    "    'sigma': 0.1,            # Provided in command line args\n",
    "    'eta': 0.0,                # Provided in command line args\n",
    "    'samples': 10,           # Provided in command line args\n",
    "    'timescale': 3,          # Provided in command line args\n",
    "    'name': 'pendulum',      # Provided in command line args\n",
    "    's': 0,                  # Provided in command line args\n",
    "    'gridsize': 15,          # Default from get_args()\n",
    "    'seed': 0,               # Default from get_args()\n",
    "    'num_basis': 100,        # Provided in command line args\n",
    "    'friction': False,        # Default from get_args()\n",
    "    'train_samples': 10, \n",
    "    'val_samples': 5,\n",
    "    'datasets': 5,\n",
    "    'T': 5,\n",
    "    'radius_a': 1.,\n",
    "    'radius_b': 1.,\n",
    "    'seed': 0,\n",
    "    'save_dir': THIS_DIR,\n",
    "    'input_dim': 2\n",
    "})\n",
    "\n",
    "\n",
    "class ODE_pendulum(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.M = self.permutation_tensor(input_dim)\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        H = self.H(x)\n",
    "        dH = torch.autograd.grad(H.sum(), x)[0]\n",
    "        field = dH @ self.M.t()\n",
    "        dH[:,0] = 0\n",
    "        field = field - args.eta * dH\n",
    "        return field\n",
    "    \n",
    "    def time_derivative(self, x):\n",
    "        H = self.H(x)\n",
    "        dH = torch.autograd.grad(H.sum(), x)[0]\n",
    "        field = dH @ self.M.t()\n",
    "        dH[:,0] = 0\n",
    "        field = field - args.eta * dH\n",
    "        return field\n",
    "        \n",
    "    def H(self, coords):\n",
    "        q, p = coords[:,0], coords[:,1]\n",
    "        H = 3*(1-torch.cos(q)) + p**2\n",
    "        return H\n",
    "\n",
    "    def permutation_tensor(self,n):\n",
    "        M = torch.eye(n)\n",
    "        M = torch.cat([M[n//2:], -M[:n//2]])\n",
    "        return M\n",
    "\n",
    "class ODE_duffing(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.M = self.permutation_tensor(input_dim)\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        H = self.H(x)\n",
    "        dH = torch.autograd.grad(H.sum(), x)[0]\n",
    "        field = dH @ self.M.t()\n",
    "        dH[:,0] = 0\n",
    "        field = field - args.eta * dH\n",
    "        return field\n",
    "    \n",
    "    def time_derivative(self, x):\n",
    "        H = self.H(x)\n",
    "        dH = torch.autograd.grad(H.sum(), x)[0]\n",
    "        field = dH @ self.M.t()\n",
    "        dH[:,0] = 0\n",
    "        field = field - args.eta * dH\n",
    "        return field\n",
    "        \n",
    "    def H(self, coords):\n",
    "        if len(coords) == 2:\n",
    "            q, p = coords[0], coords[1]\n",
    "        else:\n",
    "            q, p = coords[:,0], coords[:,1]\n",
    "        H = .5*p**2 - .5*q**2 + .25*q**4\n",
    "        return H\n",
    "\n",
    "    def permutation_tensor(self,n):\n",
    "        M = torch.eye(n)\n",
    "        M = torch.cat([M[n//2:], -M[:n//2]])\n",
    "        return M\n",
    "\n",
    "def vis_obs(save_dir, field, data, trajectory_name):\n",
    "    y = data[trajectory_name]\n",
    "    t_eval = data['t']\n",
    "    fig = plt.figure(figsize=(11.3, 21), facecolor='white', dpi=DPI)\n",
    "    N = y.shape[0]\n",
    "    N = 28 if N > 28 else N\n",
    "    for i in range(N):\n",
    "        t = torch.tensor(np.linspace(0, t_eval[-1], t_eval.shape[0]))\n",
    "        ax = fig.add_subplot(math.ceil(N/4), 4, i+1, frameon=True)\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "        ax.quiver(field['x'][:,0], field['x'][:,1], field['dx'][:,0], field['dx'][:,1],\n",
    "                   scale=ARROW_SCALE, width=ARROW_WIDTH,\n",
    "                   cmap='gray_r', color=(.5,.5,.5))\n",
    "        ax.scatter(y[i][:,0], y[i][:,1], c=t, s=16, cmap='coolwarm')\n",
    "        plt.axis([xmin, xmax, ymin, ymax])\n",
    "        plt.xlabel(\"$q$\", fontsize=12)\n",
    "        plt.ylabel(\"$p$\", rotation=0, fontsize=12)\n",
    "        plt.title(\"Sample \" + str(i+1))\n",
    "    plt.tight_layout()\n",
    "    fig.savefig('{}/{}.{}'.format(save_dir, trajectory_name, FORMAT))\n",
    "    plt.close()\n",
    "\n",
    "def vis_energy(save_dir, data, e_name):\n",
    "    es = data[e_name]\n",
    "    t_eval = data['t']\n",
    "    \n",
    "    fig = plt.figure(figsize=(11.3, 21), facecolor='white', dpi=DPI)\n",
    "    N = es.shape[0]\n",
    "    N = 28 if N > 28 else N\n",
    "    for i in range(N):\n",
    "        t = t_eval\n",
    "        ax = fig.add_subplot(math.ceil(N/4), 4, i+1, frameon=True)\n",
    "        ax.plot(t, es[i],'-', color='black')\n",
    "        ymax = data['es'].max()\n",
    "        ax.axis([0, args.T, 0, ymax*1.5])\n",
    "        plt.xlabel(\"time\", fontsize=12)\n",
    "        plt.ylabel(\"Energy\", rotation=90, fontsize=12)\n",
    "        plt.title(\"Sample \" + str(i+1))\n",
    "    plt.tight_layout()\n",
    "    fig.savefig('{}/{}.{}'.format(save_dir, e_name, FORMAT))\n",
    "    plt.close()\n",
    "\n",
    "def get_field(ode, xmin, xmax, ymin, ymax, gridsize):\n",
    "    field = {}\n",
    "\n",
    "    # meshgrid to get vector field\n",
    "    b, a = np.meshgrid(np.linspace(xmin, xmax, gridsize), np.linspace(ymin, ymax, gridsize))\n",
    "    x = np.stack([b.flatten(), a.flatten()]).T\n",
    "    x = torch.tensor(x, requires_grad=True)\n",
    "\n",
    "    # get vector directions\n",
    "    dx = ode.time_derivative(x)\n",
    "    field['x'] = x.detach().numpy()\n",
    "    field['dx'] = dx.detach().numpy()\n",
    "    field['mesh_a'] = a\n",
    "    field['mesh_b'] = b\n",
    "    return field\n",
    "\n",
    "def vis_field(save_dir, field, name):\n",
    "    a = field['mesh_a']\n",
    "    b = field['mesh_b']\n",
    "    fig = plt.figure(figsize=(4,3), facecolor='white', dpi=DPI)\n",
    "    ax = fig.subplots()\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    scale = ARROW_SCALE\n",
    "    ax.quiver(field['x'][:,0], field['x'][:,1], field['dx'][:,0], field['dx'][:,1],\n",
    "              scale=scale, width=ARROW_WIDTH)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig('{}/{}.{}'.format(save_dir, name, FORMAT))\n",
    "    plt.close()\n",
    "\n",
    "def get_init():\n",
    "\n",
    "    N = samples\n",
    "    if args.name in ['pendulum']:\n",
    "        np.random.seed(args.seed)\n",
    "        x0s = np.random.rand(N,2)*2.-1\n",
    "        x0s = x0s.T\n",
    "        np.random.seed(args.seed)\n",
    "        radius = np.random.rand(N,1)*args.radius_a+args.radius_b\n",
    "        x0s = (x0s / np.sqrt((x0s**2).sum(0))).T * radius\n",
    "        x0s = torch.tensor(x0s, requires_grad=True)\n",
    "\n",
    "    elif args.name in ['duffing']:\n",
    "        x0s = []\n",
    "        np.random.seed(args.seed)\n",
    "        while(1):\n",
    "            x0 = np.random.rand(2)*6.-3\n",
    "            en = ode.H(torch.tensor(x0))\n",
    "            if (args.radius_b <= en) and (en <= args.radius_a+args.radius_b):\n",
    "                x0s.append(x0)\n",
    "                if len(x0s) == N:\n",
    "                    break\n",
    "        x0s = torch.tensor(np.stack(x0s), requires_grad=True)\n",
    "\n",
    "    return x0s\n",
    "\n",
    "def path_arrange(path):\n",
    "  x = []\n",
    "  for i in range(path.shape[1]):\n",
    "    x.append(path[:,i,:])\n",
    "  return torch.stack(x)\n",
    "\n",
    "def generate_data(ode):\n",
    "\n",
    "    data = {'meta': locals()}\n",
    "    dt = 1/args.timescale\n",
    "    \n",
    "    xs, ys, dys, es = [], [], [], []\n",
    "    x0s = get_init()\n",
    "    t = torch.tensor(np.linspace(0, args.T, int(args.timescale*args.T+1)))\n",
    "    xs = odeint(ode, x0s, t, method='dopri5', atol=1e-8, rtol=1e-8)\n",
    "    xs = path_arrange(xs)\n",
    "    for x in xs:\n",
    "        e = ode.H(x)\n",
    "        es.append(e)\n",
    "    es = torch.stack(es)\n",
    "    np.random.seed(args.seed)\n",
    "    noise = np.random.normal(0,args.sigma,[xs.shape[0],xs.shape[1],xs.shape[2]])\n",
    "    ys = xs + torch.tensor(noise)\n",
    "    \n",
    "    for y in ys:\n",
    "        dy = torch.diff(y, dim=0) / dt\n",
    "        dys.append(dy)\n",
    "    dys = torch.stack(dys)\n",
    "\n",
    "    data['xs'] = xs.detach().numpy()\n",
    "    data['ys'] = ys.detach().numpy()\n",
    "    data['dys'] = dys.detach().numpy()\n",
    "    data['t'] = t.detach().numpy()\n",
    "    data['es'] = es.detach().numpy()\n",
    "    field = get_field(ode, xmin, xmax, ymin, ymax, args.gridsize)\n",
    "\n",
    "    vis_obs(save_dir, field, data, trajectory_name='xs')\n",
    "    vis_obs(save_dir, field, data, trajectory_name='ys')\n",
    "    vis_field(save_dir, field, 'field')\n",
    "    vis_energy(save_dir, data, e_name='es')\n",
    "    return data\n",
    "\n",
    "def split(s):\n",
    "    train_split_id = args.train_samples\n",
    "    ids = [i for i in range(samples)]\n",
    "    if samples == 10:\n",
    "        np.random.seed(s)\n",
    "        np.random.shuffle(ids)\n",
    "        train_ids = ids[:train_split_id]; val_ids = ids[train_split_id:]\n",
    "    else:\n",
    "        if samples == 15:\n",
    "            prev_samples = 10\n",
    "        elif samples == 20:\n",
    "            prev_samples = 15\n",
    "        elif samples == 30:\n",
    "            prev_samples = 20\n",
    "        elif samples == 50:\n",
    "            prev_samples = 30\n",
    "            \n",
    "        prev_dir = ( args.save_dir + '/' + args.name  + '/' + str(args.eta) + '/train/'\n",
    "                    + str(args.sigma) + '/' + str(prev_samples) + '/' + str(args.timescale))\n",
    "        filename = prev_dir + '/' + str(s) + '/train_ids.csv'\n",
    "        train_ids = csv_read(filename)\n",
    "        train_ids = list(np.array(train_ids[0]).astype(int))\n",
    "\n",
    "        a_ids = tuple(set(ids) - set(train_ids))\n",
    "        a_ids = [a_ids[i] for i in range(len(a_ids))]\n",
    "        a_samples = train_split_id - len(train_ids)\n",
    "\n",
    "        np.random.seed(s)\n",
    "        np.random.shuffle(a_ids)\n",
    "        train_ids.extend(a_ids[:a_samples]); val_ids = a_ids[a_samples:]\n",
    "\n",
    "    split_data = {}\n",
    "    for k in ['xs', 'ys', 'dys', 'es']:\n",
    "        split_data['val_' + k], split_data[k] = data[k][val_ids], data[k][train_ids]\n",
    "    split_data['val_t'], split_data['t'] = data['t'], data['t']\n",
    "\n",
    "    return split_data, train_ids\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    samples = args.train_samples + args.val_samples\n",
    "    if args.name == 'pendulum':\n",
    "        ode = ODE_pendulum(args.input_dim)\n",
    "    elif args.name == 'duffing':\n",
    "        ode = ODE_duffing(args.input_dim)\n",
    "\n",
    "    save_dir = ( args.save_dir + '/' + args.name  + '/' + str(args.eta) + '/train/' + str(args.sigma)\n",
    "                 + '/' + str(samples) + '/' + str(args.timescale))\n",
    "    os.makedirs(save_dir) if not os.path.exists(save_dir) else None\n",
    "    data = generate_data(ode)\n",
    "    pkl_write(save_dir + '/data.pkl', data)\n",
    "    field = get_field(ode, xmin, xmax, ymin, ymax, args.gridsize)\n",
    "    pkl_write(save_dir + '/field.pkl', field)\n",
    "\n",
    "    for s in range(args.datasets):\n",
    "        split_data, train_ids = split(s)\n",
    "        save_dir_s = save_dir + '/' + str(s)\n",
    "        os.makedirs(save_dir_s) if not os.path.exists(save_dir_s) else None\n",
    "        pkl_write(save_dir_s + '/dataset.pkl', split_data)\n",
    "        csv_write(save_dir_s + '/train_ids.csv', train_ids)\n",
    "\n",
    "        vis_obs(save_dir_s, field, split_data, trajectory_name='ys')\n",
    "        vis_obs(save_dir_s, field, split_data, trajectory_name='val_ys')\n",
    "        \n",
    "\n",
    "    filename = '{}/{}.json'.format(save_dir, args.name)\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(vars(args), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symplectic Spectrum Gaussian Processes | 2022\n",
    "# Yusuke Tanaka\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "dpi=100\n",
    "sns.set()\n",
    "sns.set_style(\"whitegrid\", {'grid.linestyle': '--'})\n",
    "sns.set_context(\"paper\", 1.5, {\"lines.linewidth\": 1.5})\n",
    "sns.set_palette(\"deep\")\n",
    "\n",
    "def plot(file, x, ys, xlabel, ylabel, legend):\n",
    "    colors = ['blue','orange','green']\n",
    "    fig = plt.figure(figsize=(8, 4), facecolor='white', dpi=dpi)\n",
    "    for i in range(2):\n",
    "        ax = fig.add_subplot(1, 2, i+1, frameon=True)\n",
    "        ax.plot(x, ys[i], c=colors[i])\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(ylabel)\n",
    "        plt.title(legend[i])\n",
    "        ax.yaxis.offsetText.set_fontsize(16)\n",
    "        plt.gca().ticklabel_format(style=\"sci\", scilimits=(0,0), axis=\"y\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(file, format='pdf')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symplectic Spectrum Gaussian Processes | 2022\n",
    "# Yusuke Tanaka\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import os, torch, pickle, zipfile\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pdb\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "DPI = 200\n",
    "FORMAT = 'pdf'\n",
    "LINE_SEGMENTS = 10\n",
    "ARROW_SCALE = 100\n",
    "ARROW_WIDTH = 6e-3\n",
    "LINE_WIDTH = 2\n",
    "xmin = -3.2; xmax = 3.2; ymin = -3.2; ymax = 3.2\n",
    "\n",
    "\n",
    "def get_batch(args, x, t_eval, batch_step):\n",
    "  n_samples, n_points, input_dim = x.shape\n",
    "  N = n_samples\n",
    "  n_ids = torch.from_numpy(np.arange(N))\n",
    "  p_ids = torch.from_numpy(np.random.choice(np.arange(n_points-batch_step, dtype=np.int64), N, replace=True))\n",
    "  batch_x0 = x[n_ids,p_ids].reshape([N,1,input_dim])\n",
    "  batch_step += 1\n",
    "  batch_t = t_eval[:batch_step]\n",
    "  batch_x = ( torch.stack([x[n_ids, p_ids+i] for i in range(batch_step)], dim=0)\n",
    "              .reshape([batch_step,N,1,input_dim]) )\n",
    "  return batch_x0, batch_t, batch_x\n",
    "\n",
    "def arrange(args, x, t_eval):\n",
    "  n_samples, n_points, input_dim = x.shape\n",
    "  n_ids = np.arange(n_samples, dtype=np.int64)\n",
    "  p_ids = np.array([0]*n_samples)\n",
    "  batch_x0 = x[n_ids,p_ids].reshape([n_samples,1,input_dim])\n",
    "  batch_t = t_eval\n",
    "  batch_x = torch.stack([x[n_ids, p_ids+i] for i in range(n_points)],dim=0).reshape([n_points,n_samples,1,input_dim])\n",
    "  return batch_x0, batch_t, batch_x\n",
    "\n",
    "def get_field(func, xmin, xmax, ymin, ymax, gridsize):\n",
    "  field = {'meta': locals()}\n",
    "\n",
    "  # meshgrid to get vector field\n",
    "  b, a = np.meshgrid(np.linspace(xmin, xmax, gridsize), np.linspace(ymin, ymax, gridsize))\n",
    "  ys = np.stack([b.flatten(), a.flatten()])\n",
    "  ys = torch.tensor( ys, dtype=torch.float64, requires_grad=True).t()\n",
    "\n",
    "  # get vector directions\n",
    "  dydt = func(torch.tensor([0]),ys)\n",
    "  field['x'] = ys.cpu().detach().numpy()\n",
    "  field['dx'] = dydt.squeeze().cpu().detach().numpy()\n",
    "  field['mesh_a'] = a\n",
    "  field['mesh_b'] = b\n",
    "  return field\n",
    "\n",
    "def vis_path(filename, field, y, t, xmin, xmax, ymin, ymax):\n",
    "  fig = plt.figure(figsize=(21, 11.3), facecolor='white', dpi=DPI)\n",
    "  N = y.shape[0]\n",
    "  N = 28 if N > 28 else N\n",
    "  for i in range(N):\n",
    "    ax = fig.add_subplot(math.ceil(N/7), 7, i+1, frameon=True)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.quiver(field['x'][:,0], field['x'][:,1], field['dx'][:,0], field['dx'][:,1],\n",
    "              scale=ARROW_SCALE, width=ARROW_WIDTH,\n",
    "              cmap='gray_r', color=(.5,.5,.5))\n",
    "    ax.scatter(y[i][:,0], y[i][:,1], c=t, s=0.5, cmap='coolwarm')\n",
    "    plt.axis([xmin, xmax, ymin, ymax])\n",
    "    plt.xlabel(\"$x_q$\", fontsize=12)\n",
    "    plt.ylabel(\"$x_p$\", rotation=0, fontsize=12)\n",
    "    plt.title(\"Sample \" + str(i+1))\n",
    "    plt.grid(False)\n",
    "  plt.tight_layout()\n",
    "  fig.savefig(filename)\n",
    "  plt.close()\n",
    "\n",
    "def vis_path_2d(filename, y, t_eval):\n",
    "  fig = plt.figure(figsize=(21, 11.3), facecolor='white', dpi=DPI)\n",
    "  N = y.shape[0]\n",
    "  N = 28 if N > 28 else N\n",
    "  for i in range(N):\n",
    "    xs1 = y[i,:,0]; xs2 = y[i,:,1]\n",
    "    ax = fig.add_subplot(math.ceil(N/7), 7, i+1, frameon=True)\n",
    "    ax.scatter(t_eval, xs1, s=0.5)\n",
    "    ax.scatter(t_eval, xs2, s=0.5)\n",
    "    plt.axis([t_eval.min().item(), t_eval.max().item(), -3, 3])\n",
    "    plt.xlabel(\"$t$\", fontsize=12)\n",
    "    plt.ylabel(\"$x_q$\", rotation=0, fontsize=12)\n",
    "    plt.title(\"Sample \" + str(i+1))\n",
    "    plt.grid(False)\n",
    "  plt.tight_layout()\n",
    "  fig.savefig(filename)\n",
    "  plt.close()\n",
    "\n",
    "def vis_field(filename, field, xmin, xmax, ymin, ymax):\n",
    "  fig = plt.figure(figsize=(4,3), facecolor='white', dpi=DPI)\n",
    "  ax = fig.subplots()\n",
    "  ax.set_aspect('equal', adjustable='box')\n",
    "  scale = ARROW_SCALE\n",
    "  ax.quiver(field['x'][:,0], field['x'][:,1], field['dx'][:,0], field['dx'][:,1],\n",
    "            scale=scale, width=ARROW_WIDTH,\n",
    "            cmap='gray_r', color=(.5,.5,.5))\n",
    "  plt.axis([xmin, xmax, ymin, ymax])\n",
    "  plt.xlabel(\"$x_q$\", fontsize=12)\n",
    "  plt.ylabel(\"$x_p$\", rotation=0, fontsize=12)\n",
    "  plt.grid(False)\n",
    "  plt.tight_layout()\n",
    "  fig.savefig(filename)\n",
    "  plt.close()\n",
    "\n",
    "def vis_err(filename, es, t):\n",
    "  fig = plt.figure(figsize=(21, 11.3), facecolor='white', dpi=DPI)\n",
    "  N = es.shape[0]\n",
    "  N = 28 if N > 28 else N\n",
    "  for i in range(N):\n",
    "    ax = fig.add_subplot(math.ceil(N/7), 7, i+1, frameon=True)\n",
    "    ax.plot(t, es[i],'-', color='black')\n",
    "    ax.axis([0, t.max(), 0, es.max()*1.2])\n",
    "    plt.xlabel(\"time\", fontsize=12)\n",
    "    plt.ylabel(\"MSE\", rotation=90, fontsize=12)\n",
    "    plt.title(\"Sample \" + str(i+1))\n",
    "  plt.tight_layout()\n",
    "  fig.savefig(filename)\n",
    "  plt.close()\n",
    "\n",
    "def vis_energy(filename, true, es, t):\n",
    "  fig = plt.figure(figsize=(21, 11.3), facecolor='white', dpi=DPI)\n",
    "  N = es.shape[0]\n",
    "  N = 28 if N > 28 else N\n",
    "  if es.max() > 0:\n",
    "    ymax = es.max() if true.max() < es.max() else true.max()\n",
    "  else:\n",
    "    ymax = es.min() if true.min() > es.min() else true.min()\n",
    "  for i in range(N):\n",
    "    ax = fig.add_subplot(math.ceil(N/7), 7, i+1, frameon=True)\n",
    "    ax.plot(t, true[i],'-', color='black')\n",
    "    ax.plot(t, es[i],'-', color='red')\n",
    "    ax.axis([0, t.max(), 0, ymax*1.2])\n",
    "    plt.xlabel(\"time\", fontsize=12)\n",
    "    plt.ylabel(\"Energy\", rotation=90, fontsize=12)\n",
    "    plt.title(\"Sample \" + str(i+1))\n",
    "  plt.tight_layout()\n",
    "  fig.savefig(filename)\n",
    "  plt.close()\n",
    "\n",
    "def path_arrange(path):\n",
    "  x = []\n",
    "  for i in range(path.shape[1]):\n",
    "    x.append(path[:,i,:])\n",
    "  return torch.stack(x)\n",
    "\n",
    "def d_pendulum_energy(coords):\n",
    "  q1, q2, p1, p2 = coords[:,:,0], coords[:,:,1], coords[:,:,2], coords[:,:,3]\n",
    "  m1 = .2; m2 = .1\n",
    "  H = ( (m2*p1**2 + (m1+m2)*p2**2 - 2*m2*p1*p2*np.cos(q1-q2))\n",
    "        / (2*m2*(m1+m2*np.sin(q1-q2)**2))\n",
    "        - (m1+m2)*9.8*np.cos(q1)\n",
    "        - m2*9.8*np.cos(q2) )\n",
    "  return H\n",
    "\n",
    "def pendulum_energy(coords):\n",
    "    qs = coords[:,:,0]; ps = coords[:,:,1]\n",
    "    energy = 3*(1-np.cos(qs)) + ps**2\n",
    "    return energy\n",
    "\n",
    "def duffing_energy(coords):\n",
    "    qs = coords[:,:,0]; ps = coords[:,:,1]\n",
    "    energy= .5*ps**2 - .5*qs**2 + .25*qs**4\n",
    "    return energy\n",
    "\n",
    "def real_pend_energy(coords):\n",
    "    qs = coords[:,:,0]; ps = coords[:,:,1]\n",
    "    energy = 2.4*(1-np.cos(qs)) + ps**2\n",
    "    return energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "##This code is served in https://github.com/steveli/pytorch-sqrtm.git\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "\n",
    "\n",
    "class MatrixSquareRoot(Function):\n",
    "    \"\"\"Square root of a positive definite matrix.\n",
    "\n",
    "    NOTE: matrix square root is not differentiable for matrices with\n",
    "          zero eigenvalues.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        m = input.detach().cpu().numpy().astype(np.float_)\n",
    "        sqrtm = torch.from_numpy(scipy.linalg.sqrtm(m).real).to(input)\n",
    "        ctx.save_for_backward(sqrtm)\n",
    "        return sqrtm\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        grad_input = None\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            sqrtm, = ctx.saved_tensors\n",
    "            sqrtm = sqrtm.data.cpu().numpy().astype(np.float_)\n",
    "            gm = grad_output.data.cpu().numpy().astype(np.float_)\n",
    "\n",
    "            # Given a positive semi-definite matrix X,\n",
    "            # since X = X^{1/2}X^{1/2}, we can compute the gradient of the\n",
    "            # matrix square root dX^{1/2} by solving the Sylvester equation:\n",
    "            # dX = (d(X^{1/2})X^{1/2} + X^{1/2}(dX^{1/2}).\n",
    "            grad_sqrtm = scipy.linalg.solve_sylvester(sqrtm, sqrtm, gm)\n",
    "\n",
    "            grad_input = torch.from_numpy(grad_sqrtm).to(grad_output)\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "sqrtm = MatrixSquareRoot.apply\n",
    "\n",
    "\n",
    "def main():\n",
    "    from torch.autograd import gradcheck\n",
    "    k = torch.randn(20, 10).double()\n",
    "    # Create a positive definite matrix\n",
    "    pd_mat = (k.t().matmul(k)).requires_grad_()\n",
    "    test = gradcheck(sqrtm, (pd_mat,))\n",
    "    print(test)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symplectic Spectrum Gaussian Processes | 2022\n",
    "# Yusuke Tanaka\n",
    "\n",
    "import sys\n",
    "import pdb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "\n",
    "class SSGP(torch.nn.Module):\n",
    "  def __init__(self, input_dim, basis, friction):\n",
    "    super(SSGP, self).__init__()\n",
    "    self.sigma = nn.Parameter(torch.tensor([1e-1]))\n",
    "    self.a = nn.Parameter(torch.ones(input_dim)*1e-1)\n",
    "    self.b = nn.Parameter(1e-4 * (torch.rand(basis*2)-0.5))\n",
    "    self.init_C(basis)\n",
    "    self.sigma_0 = nn.Parameter(torch.tensor([1e-0]))\n",
    "    self.lam = nn.Parameter(torch.ones(input_dim)*1.5)\n",
    "    if friction:\n",
    "      self.eta = nn.Parameter(torch.tensor([1e-16]))\n",
    "    else:\n",
    "      self.eta = torch.tensor([0.0])\n",
    "    self.M = self.permutation_tensor(input_dim)\n",
    "    np.random.seed(0)\n",
    "    tmp = torch.tensor(np.random.normal(0, 1, size=(int(basis/2.), input_dim)))\n",
    "    self.epsilon = torch.vstack([tmp,-tmp])\n",
    "    self.d = input_dim\n",
    "    self.num_basis = basis\n",
    "\n",
    "  def sampling_epsilon_f(self):\n",
    "    C = self.make_C()\n",
    "    sqrt_C = sqrtm(C)\n",
    "    sqrt_C = torch.block_diag(sqrt_C,sqrt_C)\n",
    "    epsilon = torch.tensor(np.random.normal(0, 1, size=(1,sqrt_C.shape[0]))).T\n",
    "    self.w = self.b + (sqrt_C @ epsilon).squeeze()\n",
    "    num = 99\n",
    "    for i in range(num):\n",
    "      epsilon = torch.tensor(np.random.normal(0, 1, size=(1,sqrt_C.shape[0]))).T\n",
    "      self.w += self.b + (sqrt_C @ epsilon).squeeze()\n",
    "    self.w = self.w/(num+1)\n",
    "\n",
    "  def mean_w(self):\n",
    "    self.w = self.b * 1\n",
    "    \n",
    "  def forward(self, t, x):\n",
    "    s = self.epsilon @ torch.diag((1 / torch.sqrt(4*math.pi**2 * self.lam**2)))\n",
    "    R = torch.eye(self.d)\n",
    "    R[:int(self.d/2),:int(self.d/2)] = 0\n",
    "    mat = 2*math.pi*((self.M-self.eta**2*R)@s.T).T\n",
    "    x = x.squeeze()\n",
    "    samples = x.shape[0]\n",
    "    sim = 2*math.pi*s@x.squeeze().T\n",
    "    basis_s = -torch.sin(sim); basis_c = torch.cos(sim)\n",
    "\n",
    "    # deterministic\n",
    "    tmp = []\n",
    "    for i in range(self.d):\n",
    "      tmp.extend([mat[:,i]]*samples)\n",
    "    tmp = torch.stack(tmp).T\n",
    "    aug_mat = torch.vstack([tmp,tmp])\n",
    "    aug_s = torch.hstack([basis_s]*self.d); aug_c = torch.hstack([basis_c]*self.d)\n",
    "    aug_basis = torch.vstack([aug_s, aug_c])\n",
    "    PHI = aug_mat * aug_basis\n",
    "    aug_W = torch.stack([self.w]*samples*self.d).T\n",
    "    F = PHI * aug_W\n",
    "    f = torch.vstack(torch.split(F.sum(axis=0),samples)).T\n",
    "    return f.reshape([samples,1,self.d])\n",
    "\n",
    "  def neg_loglike(self, batch_x, pred_x):\n",
    "    n_samples, n_points, dammy, input_dim = batch_x.shape\n",
    "    likelihood = ( (-(pred_x-batch_x)**2/self.sigma**2/2).nansum()\n",
    "                   - torch.log(self.sigma**2)/2*n_samples*n_points*input_dim)\n",
    "    return -likelihood\n",
    "\n",
    "  def KL_x0(self, x0):\n",
    "    n, d = x0.shape\n",
    "    S = torch.diag(self.a**2)\n",
    "    return .5*((x0*x0).sum() + n*torch.trace(S) - n*torch.logdet(S))\n",
    "\n",
    "  def KL_w(self):\n",
    "    num = self.b.shape[0]\n",
    "    C = self.make_C()\n",
    "    C = torch.block_diag(C,C)\n",
    "    term3 = (self.b*self.b).sum() / (self.sigma_0**2 / num * 2)\n",
    "    term2 = torch.diag(C).sum() / (self.sigma_0**2 / num * 2)\n",
    "    term1_1 = torch.log(self.sigma_0**2 / num * 2) * num\n",
    "    term1_2 = torch.logdet(C)\n",
    "    return .5*( term1_1 - term1_2 + term2 + term3)\n",
    "\n",
    "  def sampling_x0(self, x0):\n",
    "    n, _, d = x0.shape\n",
    "    return (x0 + torch.sqrt(torch.stack([self.a**2]*n).reshape([n,1,d]))\n",
    "            * (torch.normal(0,1, size=(x0.shape[0],1,x0.shape[2]))))\n",
    "\n",
    "  def permutation_tensor(self,n):\n",
    "    M = torch.eye(n)\n",
    "    M = torch.cat([M[n//2:], -M[:n//2]])\n",
    "    return M\n",
    "\n",
    "  def init_C(self, basis):\n",
    "    C = torch.linalg.cholesky(torch.ones(basis,basis)*1e-2+torch.eye(basis)*1e-2)\n",
    "    C_line = C.reshape([(basis)**2])\n",
    "    ids = torch.where(C_line!=0)[0]\n",
    "    self.c = nn.Parameter(C_line[ids])\n",
    "    ids = []\n",
    "    for i in range(basis):\n",
    "      for j in range(i+1):\n",
    "        ids.append([i,j])\n",
    "    ids = torch.tensor(ids)\n",
    "    self.ids0 = ids[:,0]\n",
    "    self.ids1 = ids[:,1]\n",
    "    \n",
    "  def make_C(self):\n",
    "    C = torch.zeros(self.num_basis,self.num_basis)\n",
    "    C[self.ids0,self.ids1] = self.c\n",
    "    C = C@C.T\n",
    "    return C\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.001\n",
      "./pendulum/0.0/train/0.1/10/3/0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects a non-empty TensorList",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 125\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# learning\u001b[39;00m\n\u001b[1;32m    124\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 125\u001b[0m model, stats, train_loss, val_loss, step \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m train_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# save\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 70\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     69\u001b[0m     batch_y0, batch_t, batch_ys \u001b[38;5;241m=\u001b[39m arrange(args, val_ys, t_eval)\n\u001b[0;32m---> 70\u001b[0m     s_batch_x0 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_x0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_y0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     model\u001b[38;5;241m.\u001b[39mmean_w()\n\u001b[1;32m     72\u001b[0m     pred_val_x \u001b[38;5;241m=\u001b[39m odeint(model, s_batch_x0, t_eval, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdopri5\u001b[39m\u001b[38;5;124m'\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 95\u001b[0m, in \u001b[0;36mSSGP.sampling_x0\u001b[0;34m(self, x0)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msampling_x0\u001b[39m(\u001b[38;5;28mself\u001b[39m, x0):\n\u001b[1;32m     94\u001b[0m   n, _, d \u001b[38;5;241m=\u001b[39m x0\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 95\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (x0 \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape([n,\u001b[38;5;241m1\u001b[39m,d]))\n\u001b[1;32m     96\u001b[0m           \u001b[38;5;241m*\u001b[39m (torch\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39m(x0\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m1\u001b[39m,x0\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]))))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects a non-empty TensorList"
     ]
    }
   ],
   "source": [
    "# Symplectic Spectrum Gaussian Processes | 2022\n",
    "# Yusuke Tanaka\n",
    "\n",
    "#os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'\n",
    "#num_threads = '1'\n",
    "#os.environ['OMP_NUM_THREADS'] = num_threads\n",
    "#os.environ['MKL_NUM_THREADS'] = num_threads\n",
    "#os.environ['NUMEXPR_NUM_THREADS'] = num_threads\n",
    "\n",
    "import pdb\n",
    "import os, sys\n",
    "import copy\n",
    "import time\n",
    "import json\n",
    "import argparse\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchdiffeq import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "%pwd\n",
    "THIS_DIR = %pwd  # This will set THIS_DIR to the current working directory\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "DPI = 200\n",
    "FORMAT = 'pdf'\n",
    "LINE_SEGMENTS = 10\n",
    "ARROW_SCALE = 100\n",
    "ARROW_WIDTH = 6e-3\n",
    "LINE_WIDTH = 2\n",
    "xmin = -3.2; xmax = 3.2; ymin = -3.2; ymax = 3.2\n",
    "\n",
    "\n",
    "# Now you can access the arguments using dot notation\n",
    "print(args.batch_time)\n",
    "print(args.learn_rate)\n",
    "\n",
    "def train():\n",
    "    # set random seed\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "\n",
    "    # init model and optimizer\n",
    "    output_dim = input_dim\n",
    "    model = SSGP(input_dim, args.num_basis, args.friction).double()\n",
    "    optim = torch.optim.Adam(model.parameters(), args.learn_rate)\n",
    "\n",
    "    # train loop\n",
    "    stats = {'train_loss': [], 'val_loss': []}\n",
    "    t0 = time.time()\n",
    "    min_val_loss = 1e+10\n",
    "    for step in range(args.total_steps+1):\n",
    "\n",
    "        # train step\n",
    "        batch_y0, batch_t, batch_ys = get_batch(args, ys, t_eval, batch_step)\n",
    "        s_batch_x0 = model.sampling_x0(batch_y0)\n",
    "        model.sampling_epsilon_f()\n",
    "        pred_x = odeint(model, s_batch_x0, batch_t, method='dopri5', atol=1e-8, rtol=1e-8)\n",
    "        neg_loglike = model.neg_loglike(batch_ys, pred_x)\n",
    "        KL_x0 = model.KL_x0(batch_y0.squeeze())\n",
    "        KL_w = model.KL_w()\n",
    "        loss = neg_loglike + KL_x0 + KL_w\n",
    "        loss.backward(); optim.step(); optim.zero_grad()\n",
    "        train_loss = loss.detach().item()/batch_y0.shape[0]/batch_t.shape[0]\n",
    "        # run validation data\n",
    "        with torch.no_grad():\n",
    "            batch_y0, batch_t, batch_ys = arrange(args, val_ys, t_eval)\n",
    "            s_batch_x0 = model.sampling_x0(batch_y0)\n",
    "            model.mean_w()\n",
    "            pred_val_x = odeint(model, s_batch_x0, t_eval, method='dopri5', atol=1e-8, rtol=1e-8)\n",
    "            val_neg_loglike = model.neg_loglike(batch_ys, pred_val_x)\n",
    "            loss = val_neg_loglike\n",
    "            val_loss = loss.item()/batch_y0.shape[0]/t_eval.shape[0]\n",
    "\n",
    "        # logging\n",
    "        stats['train_loss'].append(train_loss)\n",
    "        stats['val_loss'].append(val_loss)\n",
    "        if step % args.print_every == 0:\n",
    "            print(\"step {}, time {:.2e}, train_loss {:.4e}, val_loss {:.4e}\"\n",
    "                  .format(step, time.time()-t0, train_loss, val_loss))\n",
    "            t0 = time.time()\n",
    "\n",
    "        if val_loss < min_val_loss:\n",
    "            best_model = copy.deepcopy(model)\n",
    "            min_val_loss = val_loss; best_train_loss = train_loss\n",
    "            best_step = step\n",
    "            \n",
    "    return best_model, stats, best_train_loss, min_val_loss, best_step\n",
    "\n",
    "def param_save(model):\n",
    "    csv_write(save_dir + '/' + 'sigma.csv', model['sigma'].cpu().detach().numpy())\n",
    "    csv_write(save_dir + '/' + 'a.csv', model['a'].cpu().detach().numpy())\n",
    "    csv_write(save_dir + '/' + 'b.csv', model['b'].cpu().detach().numpy())\n",
    "    csv_write(save_dir + '/' + 'c.csv', model['c'].cpu().detach().numpy())\n",
    "    csv_write(save_dir + '/' + 'sigma_0.csv', model['sigma_0'].cpu().detach().numpy())\n",
    "    csv_write(save_dir + '/' + 'lam.csv', model['lam'].cpu().detach().numpy())\n",
    "    if args.friction:\n",
    "        csv_write(save_dir + '/' + 'eta.csv', model['eta'].cpu().detach().numpy())\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # setting\n",
    "    label = 'SSGP/' + str(args.num_basis)\n",
    "    i_dir = ( './' + args.name + '/' + str(args.eta) + '/train/' + str(args.sigma) \n",
    "              + '/' + str(args.samples) + '/' + str(args.timescale) + '/' + str(args.s))\n",
    "    print(i_dir)\n",
    "    save_dir = ( './' + args.name + '/' + str(args.eta) + '/result/' + str(args.sigma) \n",
    "                 + '/' + str(args.samples) + '/' + str(args.timescale) + '/' + str(args.s) + '/' + label)\n",
    "    os.makedirs(save_dir) if not os.path.exists(save_dir) else None\n",
    "\n",
    "    # input\n",
    "    filename = i_dir + '/dataset.pkl'\n",
    "    data = pkl_read(filename)\n",
    "    ys = torch.tensor( data['ys'], requires_grad=False)\n",
    "    val_ys = torch.tensor( data['val_ys'], requires_grad=False)\n",
    "    t_eval = torch.tensor( data['t'])\n",
    "    n_samples, n_points, input_dim = ys.shape\n",
    "    batch_step = int(((len(t_eval)-1)/t_eval[-1]).item() * args.batch_time)\n",
    "\n",
    "    # learning\n",
    "    t0 = time.time()\n",
    "    model, stats, train_loss, val_loss, step = train()\n",
    "    train_time = time.time() - t0\n",
    "\n",
    "    # save\n",
    "    path = '{}/model.tar'.format(save_dir)\n",
    "    torch.save(model.state_dict(), path)\n",
    "    param_save(model.state_dict())\n",
    "    \n",
    "    path = '{}/model.json'.format(save_dir)\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(vars(args), f)\n",
    "\n",
    "    path = '{}/result.csv'.format(save_dir)\n",
    "    csv_write(path, np.array(['val_step',step,'train_loss',train_loss,\n",
    "                                     'val_loss',val_loss,'train_time',train_time]))\n",
    "\n",
    "    # vis\n",
    "    ## learning curve\n",
    "    filename = save_dir + '/learning_curve.pdf'\n",
    "    x = np.arange(len(stats['train_loss']))\n",
    "    plot(filename, x, [stats['train_loss'],stats['val_loss']],\n",
    "                  'epoch','neg_loglike', ['train','validation'])\n",
    "\n",
    "    ## pred field\n",
    "    if input_dim == 2:\n",
    "        model.mean_w()\n",
    "        pred_field = get_field(model.forward, xmin, xmax, ymin, ymax, args.gridsize)\n",
    "        filename = save_dir + '/pred_field.pdf'\n",
    "        vis_field(filename, pred_field, xmin, xmax, ymin, ymax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
